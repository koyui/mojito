<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Mojito: LLM-Aided Motion Instructor with Jitter-Reduced Inertial Tokens</title>
    <link rel="icon" type="image/png" sizes="16x16" href="images/favicon_package/android-chrome-512x512.png">

    <link rel="stylesheet" href="css/bootstrap-4.4.1.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="fonts/avenir-next/stylesheet.css">
    <link rel="stylesheet" href="fonts/segoe-print/stylesheet.css">
    <link rel="stylesheet" href="css/window.css">
    <link rel="stylesheet" href="css/carousel.css">
    <link rel="stylesheet" href="css/selection_panel.css">
    <link rel="stylesheet" href="css/main.css">
    <!-- <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"> -->
    <link rel="stylesheet" href="css/bulma-carousel.min.css">
    <link rel="stylesheet" href="css/bulma-slider.min.css">
    <!-- <link rel="stylesheet" href="css/bulma.min.css"> -->
    <link rel="stylesheet" href="css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="css/index.css">

    <script src="js/window.js"></script>
    <script src="js/carousel.js"></script>
    <script src="js/selection_panel.js"></script>
    <script src="js/generation.js"></script>
    <script src="js/editing.js"></script>
    <script src="js/application.js"></script>
    <script src="js/main.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="js/fontawesome.all.min.js"></script>
    <script src="js/bulma-carousel.min.js"></script>
    <script src="js/bulma-slider.min.js"></script>
    <script src="js/index.js"></script>
    <script src="js/video_comparison.js" defer></script>
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2><b><span class="x-gradient-font">Mojito</span>: LLM-Aided Motion Instructor with<br>Jitter-Reduced Inertial Tokens</b></h2>
            <h6>
              <a href="https://cunkaixin.netlify.app" target="_blank">Ziwei Shan</a><sup>1,*</sup>,
              <a href="https://tropinoneh.github.io/profile/" target="_blank">Yaoyu He</a><sup>1,*</sup>,
              <a href="https://afterjourney00.github.io/" target="_blank">Chengfeng Zhao</a><sup>1,*,&dagger;</sup>,
              <a href="https://alt-js.github.io/" target="_blank">Jiashen Du</a><sup>1</sup>,
              <a href="https://zhanglele12138.github.io/" target="_blank">Jingyan Zhang</a><sup>1</sup>,
              <a href="https://scholar.google.com/citations?user=YvwsqvYAAAAJ&hl=en" target="_blank">Qixuan Zhang</a><sup>1,2</sup>,
              <a href="https://scholar.google.com/citations?user=R9L_AfQAAAAJ&hl=en" target="_blank">Jingyi Yu</a><sup>1,&Dagger;</sup>,
              <a href="https://www.xu-lan.com/" target="_blank">Lan Xu</a><sup>1,&Dagger;</sup>
            </h6>
            <p style="text-align: center">
              <sup>1</sup>ShanghaiTech University &nbsp;&nbsp;
              <sup>2</sup>Deemos Technology
              <br>
              <i><sup>*</sup>Equal contributions</i>
              <br>
              <i><sup>&dagger;</sup>Project lead</i><i> &nbsp;&nbsp; <sup>&Dagger;</sup>Corresponding author</i>
            </p>
            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/abs/2312.08869" role="button"  target="_blank">
                  <i class="fa fa-file"></i> Paper </a> </p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://www.youtube.com/watch?v=MdG00uakBa8" role="button"  target="_blank">
                  <i class="fab fa-youtube"></i> Video </a> </p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/AfterJourney00/mojito" role="button"  target="_blank">
                  <i class="fab fa-github"></i> Code & Data </a> </p>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="row" style="margin-bottom:5px">
            <div class="col" style="text-align:center">
              <img src="images/teaser.png" width="90%">
            </div>
          </div>
          <div id="abstract" class="x-gradient-block">
            Human bodily movements convey critical insights into action intentions and cognitive processes, yet existing multimodal systems primarily focused on understanding human motion via language, vision, and audio, which struggle to capture the dynamic forces and torques inherent in 3D motion. Inertial measurement units (IMUs) present a promising alternative, offering lightweight, wearable, and privacy-conscious motion sensing. However, processing of streaming IMU data faces challenges such as wireless transmission instability, sensor noise, and drift, limiting their utility for long-term real-time motion capture (MoCap), and more importantly, online motion analysis. 
            To address these challenges, we introduce Mojito, an intelligent motion agent that integrates inertial sensing with large language models (LLMs) for interactive motion capture and behavioral analysis. The core innovation of Mojito lies in a jitter-reduced inertial token representation with a novel IMU signal encoding framework, and an extended language model involving inertial tokens. By employing VQVAE, Mojito learns a discrete latent space of continuous IMU signals, mitigating sensor noise and drift through quantization. The inertial tokens are then aligned with inductive bias of natural language and mapped to textual semantics to enhance compatibility with LLMs, enabling efficient sequence modeling. 
            To support domain-specific applications, Mojito further incorporates tunable LoRA adapters, facilitating personalized feedback tailored to roles such as fitness trainers or rehabilitation therapists. 
            Extensive experiments demonstrate that Mojito outperforms existing IMU-based methods in motion capture under noisy conditions, and achieves comparable behavior analysis capability compared to large vision-language models. The user study further highlights its practical effectiveness in various scenarios as a versatile tool for intelligent human-agent interaction.
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- pipeline -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title"><div class="x-gradient-font">Pipeline</div></div>
          <img src="images/pipeline.png" width="90%">
        </div>
      </div>
      <br>
      <p class="text-left">
        Overview of our training pipeline. We quantize continuous and jittery IMU signals to a sequence of jitter-reduced and motion-aware inertial tokens 
        by learning a IMU tokenizer through distribution matching strategy and adopt semantic aligned and LoRA fine-tuned LLM to generate precise, professional 
        and stylistic text feedback for human motion analysis.
      </p>
    </div>
  </section>

  <!-- results -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title"><div class="x-gradient-font">Demo Results</div></div>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-steve video-grid1">
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline height="100%">
                <source src="video/mojito_demo_1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline height="100%">
                <source src="video/mojito_demo_2.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline height="100%">
                <source src="video/mojito_demo_3.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>
      <br>
      <p class="text-left">
        Mojito delivers precise motion descriptions and instructions within seconds, markedly enhancing efficiency and user experience compared to vision-language models.  Here, we showcase the online interactions between user and our system for motion capture and analysis from streaming IMU data. The LLM running on our system backend responds to user's questions posted from web frontend instantly, bringing concise and professional feedback. The corresponding demonstration video and backend logging are placed aside for reference.
      </p>
    </div>
  </section>

  <!-- comparisons -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <div class="x-section-title"><div class="x-gradient-font">Qualitative MoCap Comparisons under Noisy Conditions</div></div>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-steve video-grid1">
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline height="100%">
                <source src="video/mocap_comp_1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline height="100%">
                <source src="video/mocap_comp_2.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-steve video-grid1">
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline height="100%">
                <source src="video/mocap_comp_3.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>
      <br>
      <p class="text-left">
        Compared to previous inertial posers, Mojito yields robust motion capture capabilities across diverse noisy input environments, which are commonly encountered in practical applications. Particularly, when the IMU sensor attached to the root joint is disturbed or missing, for example the three-point tracker setting in VR, our jitter-reduced inertial tokens are still capable of reconstructing reasonable full-body motions.
      </p>
    </div>
  </section>

  <!-- citation -->
  <section>
  <div class="container">
    <div class="row ">
      <div class="col-12">
        <div class="x-section-title"><div class="x-gradient-font">Citation</div></div>
        <p class="bibtex x-gradient-block">
@InProceedings{shan2025mojito,
  title   = {Mojito: LLM-Aided Motion Instructor with Jitter-Reduced Inertial Tokens},
  author  = {Shan, Ziwei and He, Yaoyu and Zhao, Chengfeng and Du, Jiashen and Zhang, Jingyan and 
             Zhang, Qixuan and Yu, Jingyi and Xu, Lan},
  journal = {arXiv preprint arXiv:2502.16175},
  year    = {2025}
}
        </p>
      </div>
    </div>
  </div>
  </section>

  <!-- bottom bar -->
  <section>
  <div id="bottombar">
    <div><b>Mojito: LLM-Aided Motion Instructor with Jitter-Reduced Inertial Tokens</b></div>
    <div>Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> and <a href="https://jeffreyxiang.github.io/" target="_blank">Jianfeng Xiang</a> for the website template</div>
  </div>
  </section>

</html>